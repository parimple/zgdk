# System Interpretowalnoci ZGDK

System interpretowalnoci dla bota Discord ZGDK, inspirowany badaniami Anthropic nad interpretowalnoci modeli AI.

##  Cel Systemu

- **Transparentno**: Ka偶da decyzja bota jest rejestrowana i mo偶e by wyjaniona
- **Debugowanie**: atwe ledzenie problem贸w i wydajnoci
- **Zaufanie**: U偶ytkownicy mog zrozumie dlaczego bot podj dan decyzj
- **Rozw贸j**: Analiza wzorc贸w pomaga w ulepszaniu bota

##  Komponenty Systemu

### 1. Decision Logger (`decision_logger.py`)
Rejestruje ka偶d decyzj podjt przez bota:

```python
# Przykad logowania decyzji o uprawnieniach
decision = bot.decision_logger.log_permission_check(
    user_id=str(ctx.author.id),
    command="ban",
    required_permissions=["administrator"],
    user_permissions=user_perms,
    result=has_permission
)
```

### 2. Feature Extractor (`feature_extractor.py`)
Wyodrbnia "cechy" z decyzji - wzorce zachowa bota:

```python
# Wyodrbnianie cech z decyzji
features = bot.feature_extractor.extract_features(decision)
# Zwraca: [("perm_admin_required", 1.0), ("mod_severity_high", 0.8)]
```

### 3. Action Explainer (`explainer.py`)
Tworzy czytelne wyjanienia dla u偶ytkownik贸w:

```python
# Wysanie wyjanienia u偶ytkownikowi
await bot.explainer.send_explanation(ctx, decision, level="detailed")
```

### 4. Command Tracer (`tracer.py`)
ledzi wykonanie komend krok po kroku:

```python
@trace_command
async def complex_command(self, ctx):
    async with bot.tracer.trace_step(ctx.trace, "validate_input"):
        # Walidacja
    
    async with bot.tracer.trace_step(ctx.trace, "process_data"):
        # Przetwarzanie
```

##  Typy Decyzji

### DecisionType Enum:
- `PERMISSION_CHECK` - Sprawdzanie uprawnie
- `MODERATION_ACTION` - Akcje moderacyjne
- `COMMAND_EXECUTION` - Wykonanie komendy
- `ROLE_ASSIGNMENT` - Przypisanie roli
- `PURCHASE_VALIDATION` - Walidacja zakupu
- `TEAM_MANAGEMENT` - Zarzdzanie dru偶yn
- `VOICE_CHANNEL` - Kanay gosowe
- `AI_INFERENCE` - Decyzje AI
- `COOLDOWN_CHECK` - Sprawdzanie cooldown贸w
- `ERROR_HANDLING` - Obsuga bd贸w

##  Cechy (Features)

System automatycznie wykrywa i ledzi cechy zachowa:

### Cechy Uprawnie:
- `perm_admin_required` - Wymaga administratora
- `perm_premium_required` - Wymaga premium
- `perm_team_leader` - Wymaga bycia liderem

### Cechy Moderacji:
- `mod_spam_detected` - Wykryto spam
- `mod_repeat_offender` - Recydywista
- `mod_severity_high` - Wysokie zagro偶enie

### Cechy Ekonomiczne:
- `econ_insufficient_funds` - Brak rodk贸w
- `econ_role_upgrade` - Upgrade rangi
- `econ_refund_calculated` - Obliczono zwrot

##  Komendy U偶ytkownika

### `/explain last [level]`
Wyjania ostatni decyzj dotyczc u偶ytkownika
- `level`: simple, detailed, technical

### `/explain command <nazwa> [limit]`
Pokazuje ostatnie decyzje dla danej komendy (admin)

### `/trace active`
Pokazuje aktywnie ledzone komendy (admin)

### `/trace performance <komenda>`
Statystyki wydajnoci komendy (admin)

### `/features map`
Mapa cech decyzyjnych bota (admin)

### `/features analyze`
Analizuje ostatni decyzj u偶ytkownika

### `/features visualize [cecha]`
Wizualizacja powiza midzy cechami

##  Integracja w Kodzie

### 1. Dodaj do nowej komendy:

```python
from core.interpretability import DecisionType
from core.interpretability.tracer import trace_command

class MyCog(commands.Cog):
    @commands.hybrid_command()
    @trace_command  # Automatyczne ledzenie
    async def my_command(self, ctx, arg):
        # Loguj decyzje
        decision = self.bot.decision_logger.log_decision(
            self.bot.decision_logger.Decision(
                decision_type=DecisionType.COMMAND_EXECUTION,
                command="my_command",
                user_id=str(ctx.author.id),
                action="execute_my_command",
                result="success",
                reason="Komenda wykonana pomylnie",
                context={"arg": arg}
            )
        )
        
        # Wylij wyjanienie jeli co poszo nie tak
        if error:
            await self.bot.explainer.send_explanation(ctx, decision)
```

### 2. Logowanie walidacji:

```python
validation_steps = [
    {
        "check": "Sprawdzenie salda",
        "passed": balance >= price,
        "reason": f"Brak rodk贸w" if balance < price else None
    },
    {
        "check": "Limit dzienny",
        "passed": daily_purchases < 10,
        "reason": "Przekroczono limit dzienny" if daily_purchases >= 10 else None
    }
]

decision = self.bot.decision_logger.log_purchase_validation(
    user_id=str(ctx.author.id),
    item="premium_role",
    price=100,
    user_balance=balance,
    validation_steps=validation_steps,
    result=all(step["passed"] for step in validation_steps)
)
```

### 3. ledzenie krok贸w:

```python
async with self.bot.tracer.trace_step(ctx.trace, "database_query"):
    # Duga operacja bazodanowa
    result = await long_database_operation()

async with self.bot.tracer.trace_step(ctx.trace, "api_call", service="discord"):
    # Wywoanie API
    await member.add_roles(role)
```

##  Analiza Wzorc贸w

System automatycznie znajduje wzorce w decyzjach:

1. **Powizane cechy** - kt贸re cechy czsto wystpuj razem
2. **Dominujce wzorce** - najczstsze typy decyzji
3. **Anomalie** - nietypowe decyzje wymagajce uwagi

##  Wizualizacja

Komenda `/features visualize` tworzy grafy pokazujce:
- Powizania midzy cechami
- Si korelacji
- Czstotliwo aktywacji

##  Bezpieczestwo

- Tylko administratorzy maj dostp do penych log贸w
- U偶ytkownicy widz tylko swoje decyzje
- Wra偶liwe dane s maskowane w logach

##  Przykady U偶ycia

### Debugowanie problemu:
```
User: Dlaczego nie mog kupi rangi?
Admin: /explain last detailed
Bot: Pokazuje szczeg贸ow analiz z krokami walidacji
```

### Analiza wydajnoci:
```
Admin: /trace performance shop
Bot: redni czas: 45.2ms, Min: 12ms, Max: 203ms
```

### Zrozumienie zachowania:
```
Admin: /features map
Bot: Pokazuje map wszystkich cech i ich powiza
```

##  Inspiracja

System inspirowany jest badaniami Anthropic nad interpretowalnoci:
- Wyodrbnianie cech (features) z zachowa
- Mapowanie powiza midzy cechami
- Manipulacja cechami (symulacja)
- Transparentno decyzji

Podobnie jak w badaniach nad Claude, nasz system pozwala:
1. Zrozumie "co bot myli" przed podjciem decyzji
2. Zobaczy kt贸re "cechy" si aktywuj
3. ledzi powizania midzy r贸偶nymi aspektami zachowania
4. Debugowa i ulepsza zachowanie bota

##  Przysze Rozszerzenia

1. **Dashboard webowy** - wizualizacja w czasie rzeczywistym
2. **Eksport raport贸w** - miesiczne analizy zachowa
3. **Alerty anomalii** - powiadomienia o nietypowych decyzjach
4. **A/B testing** - por贸wnywanie r贸偶nych strategii decyzyjnych
5. **Uczenie si** - bot uczy si z wasnych decyzji

---

System interpretowalnoci sprawia, 偶e ZGDK jest nie tylko pot偶nym botem, ale tak偶e transparentnym i godnym zaufania narzdziem, kt贸rego decyzje mo偶na zrozumie i zweryfikowa.