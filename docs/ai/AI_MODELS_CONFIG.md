# Konfiguracja Modeli AI dla ZGDK

## U≈ºywane Modele AI

Implementacja PydanticAI w projekcie u≈ºywa **zewnƒôtrznych API** - nie dzia≈Ça lokalnie. Potrzebujesz kluczy API do:

### 1. Google Gemini (REKOMENDOWANE - Najta≈Ñsze!)
- **Model**: `gemini-1.5-flash` 
- **U≈ºywane do**: Parsowanie czasu, kolor√≥w, klasyfikacja intencji
- **Koszt**: **DARMOWE** do 1 miliona token√≥w/miesiƒÖc!
- **Po przekroczeniu**: ~$0.00015 za 1000 token√≥w (10x taniej ni≈º OpenAI)

### 2. OpenAI (Alternatywa)
- **Model**: `gpt-3.5-turbo`
- **Koszt**: ~$0.002 za 1000 token√≥w

### 3. Anthropic (Opcjonalnie)
- **Model**: Claude (je≈õli chcesz zmieniƒá)
- **Koszt**: Podobny do OpenAI

## Konfiguracja Kluczy API

### Opcja 1: Zmienne ≈õrodowiskowe (.env)
```bash
# Dodaj do pliku .env (wybierz jeden)

# Google Gemini (REKOMENDOWANE - najta≈Ñsze!)
GEMINI_API_KEY=AIzaSyxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Lub OpenAI
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Lub Anthropic
ANTHROPIC_API_KEY=sk-ant-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

### Opcja 2: Bezpo≈õrednio w kodzie
```python
# W pliku core/ai/duration_parser.py
self.agent = Agent(
    'openai:gpt-3.5-turbo',
    api_key='sk-xxxxxxxx'  # NIE POLECAM - lepiej u≈ºyƒá .env
)
```

## Jak Zdobyƒá Klucze API

### Google Gemini (REKOMENDOWANE! üéâ)
1. Id≈∫ na https://makersuite.google.com/app/apikey
2. Zaloguj siƒô kontem Google
3. Kliknij "Create API Key"
4. Wybierz projekt lub stw√≥rz nowy
5. Skopiuj klucz
6. **DARMOWY LIMIT**: 1 milion token√≥w/miesiƒÖc!

### OpenAI
1. Id≈∫ na https://platform.openai.com
2. Zarejestruj siƒô / Zaloguj
3. Przejd≈∫ do "API Keys"
4. Kliknij "Create new secret key"
5. Skopiuj klucz (poka≈ºe siƒô tylko raz!)
6. Darmowe $5 kredyt√≥w przy rejestracji

### Anthropic
1. Id≈∫ na https://console.anthropic.com
2. Zarejestruj siƒô / Zaloguj
3. Przejd≈∫ do "API Keys"
4. Utw√≥rz nowy klucz

## Szacowane Koszty

### Z Google Gemini (REKOMENDOWANE):
- **Ma≈Ço aktywny serwer** (100 komend AI/dzie≈Ñ): **DARMOWE** ‚úÖ
- **≈örednio aktywny** (500 komend AI/dzie≈Ñ): **DARMOWE** ‚úÖ
- **Bardzo aktywny** (2000+ komend AI/dzie≈Ñ): **DARMOWE** lub ~$1-5/miesiƒÖc

### Z OpenAI:
- **Ma≈Ço aktywny serwer** (100 komend AI/dzie≈Ñ): ~$1-2/miesiƒÖc
- **≈örednio aktywny** (500 komend AI/dzie≈Ñ): ~$5-10/miesiƒÖc
- **Bardzo aktywny** (2000+ komend AI/dzie≈Ñ): ~$20-50/miesiƒÖc

## Tryb Bez AI (Fallback)

Wszystkie modu≈Çy majƒÖ tryb fallback - dzia≈ÇajƒÖ bez AI, ale z ograniczonƒÖ funkcjonalno≈õciƒÖ:

```python
# Wy≈ÇƒÖczenie AI w module
duration_parser = DurationParser(use_ai=False)  # Tylko podstawowe parsowanie
color_parser = ColorParser(use_ai=False)        # Tylko hex/rgb/podstawowe nazwy
```

## Zmiana Modelu

### Na Google Gemini (REKOMENDOWANE!)
```python
# W duration_parser.py, color_parser.py, etc.
self.agent = Agent(
    'google:gemini-1.5-flash',  # Szybki i darmowy!
    # 'google:gemini-1.5-pro',  # Lepszy ale dro≈ºszy
    api_key=os.getenv('GEMINI_API_KEY')
)
```

### Na ta≈Ñszy model OpenAI
```python
self.agent = Agent(
    'openai:gpt-3.5-turbo',  # Obecny (tani i dobry)
    # 'openai:gpt-4o-mini',  # Alternatywa (jeszcze ta≈Ñszy)
)
```

### Na model Anthropic
```python
self.agent = Agent(
    'anthropic:claude-3-haiku',  # Najta≈Ñszy Claude
    # 'anthropic:claude-3-sonnet', # ≈öredni
    # 'anthropic:claude-3-opus',   # Najlepszy (drogi)
)
```

### Na model lokalny (eksperymentalne)
PydanticAI wspiera lokalne modele przez Ollama:
```python
# Wymaga zainstalowania Ollama i pobrania modelu
self.agent = Agent(
    'ollama:llama2',  # Darmowy, lokalny
    # 'ollama:mistral', # Te≈º darmowy
)
```

## Optymalizacja Koszt√≥w

### 1. Cache odpowiedzi
```python
from functools import lru_cache

@lru_cache(maxsize=1000)
async def cached_parse_color(color_str: str):
    return await color_parser.parse(color_str)
```

### 2. Ograniczenie u≈ºycia
```python
# W komendach
@commands.cooldown(1, 60, commands.BucketType.user)  # 1 u≈ºycie na minutƒô
async def kolor_ai(self, ctx, *, color: str):
    # ...
```

### 3. U≈ºycie tylko dla premium
```python
if not has_premium:
    # U≈ºyj podstawowego parsera bez AI
    color = ColorInput.parse(color_str)  # Bez AI
else:
    # U≈ºyj AI dla premium
    color = await self.color_parser.parse(color_str)  # Z AI
```

## Monitorowanie U≈ºycia

### Sprawdzanie zu≈ºycia OpenAI
1. Zaloguj siƒô na https://platform.openai.com
2. Przejd≈∫ do "Usage"
3. Sprawd≈∫ dzienne/miesiƒôczne zu≈ºycie

### Logi w bocie
```python
# Dodaj logowanie u≈ºycia
logger.info(f"AI parse request: {user_id} - {command} - {tokens_used}")
```

## Rekomendacje

1. **NA START**: U≈ºyj Google Gemini - **DARMOWY** do 1M token√≥w! üéâ
2. **Ustaw limity**: W Google Cloud Console (opcjonalnie)
3. **Monitoruj**: Sprawdzaj zu≈ºycie w konsoli Google
4. **Cache agresywnie**: Te same pytania = te same odpowiedzi
5. **Fallback zawsze**: AI mo≈ºe nie dzia≈Çaƒá, bot musi dzia≈Çaƒá dalej

## Dlaczego Gemini?

‚úÖ **1 milion darmowych token√≥w miesiƒôcznie** (wystarczy na ~500k komend!)
‚úÖ **10x ta≈Ñszy po przekroczeniu** limitu ni≈º OpenAI
‚úÖ **Szybkie odpowiedzi** (gemini-1.5-flash)
‚úÖ **Wsparcie dla polskiego** jƒôzyka
‚úÖ **≈Åatwa konfiguracja** (jedno konto Google)

## Przyk≈Çad Pe≈Çnej Konfiguracji

```bash
# .env
DISCORD_TOKEN=your_discord_token

# AI - wybierz JEDEN (Gemini rekomendowane!)
GEMINI_API_KEY=AIzaSyxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx

POSTGRES_USER=zagadka
POSTGRES_PASSWORD=your_password
POSTGRES_DB=zagadka_db
POSTGRES_PORT=5432

# Opcjonalne
AI_MODEL=gemini-1.5-flash  # lub gpt-3.5-turbo
AI_MAX_TOKENS=150
AI_TEMPERATURE=0.3
AI_CACHE_TTL=3600
```

## Testowanie Bez P≈Çacenia

Mo≈ºesz przetestowaƒá podstawowƒÖ funkcjonalno≈õƒá bez AI:
```python
# Ustaw use_ai=False we wszystkich parserach
# Bot bƒôdzie dzia≈Ça≈Ç, ale bez naturalnego jƒôzyka
```

Lub u≈ºyj darmowych kredyt√≥w:
- OpenAI: $5 kredyt√≥w przy rejestracji
- Anthropic: $5 kredyt√≥w przy rejestracji